\chapter{Hardware Design and Implementation}
\section{Concepts of DeAr}
\indent 
One of the key features of the proposed DeAr DSP is manipulating Simultaneous Multi-threading (SMT) in each processing core with the purpose of exploiting arithmetic resources.
By dispatching two instruction streams that manipulate its VLIW-fashion datapath, the computational workload can be amortized by two threads simultaneously.
Another feature is exhaustively compacting the hardware resources while keeping the flexibility and computation power.
This offers the DeAr DSP better efficiency in several perspectives including power consumption, chip area and memory usage.
The compact hardware design offers DeAr good scalability.
As a result, DeAr DSP can be scaled up to multi-core architecture to meet the computational demands of data-intensive applications.
More importantly, such scalability makes DeAr very suitable for the HSA programming.
The assembly of DeAr cores forms a wavefront of HSA which supports SPMD.
Each work-item of HSA can be summited to a DeAr core and accelerated by two DeAr threads.
\\\indent Figure~\ref{fig:basicblock:a} illustrate the typical execution flow of a work-item across several basic blocks, 
each of which refers to piece of code without any branch or jump instruction except its entry and exit.
The life cycle of a work-item involves processing basic blocks and migrating among them.
The acceleration is achieved by exploiting ILP in each basic block, as shown in Figure~\ref{fig:basicblock:b}. 
At the entry of a program, two DeAr threads are forked by the hardware in replacement of a work-item.
Next, the forked DeAr threads simultaneously fetch and execute the statically-scheduled instructions to exploit ILP within the basic block.
They join at the end of the basic block, and perform an identical branch or jump instruction targeting the next basic block simultaneously.
\section{Micro-architecture Design}
In this section, we will look into DeAr from a micro-architecture perspective, and explore its design considerations at the same time.
Figure~\ref{fig:micro} illustrates the micro-architecture of DeAr DSP lane.
We adopted the concept of Harvard architecture, 
which separates data memory and instruction memory physically\cite{harvard}.
As a result, the datapath and the control path are wrapped by two independent interfaces, the load/store unit and the instruction unit, respectively.
Such orthogonality between data and instructions offers better freedom of optimizing data precision or code density.
The load/store unit supports burst mode transfer, which enable consecutive fetch of the data in the memory.
This mechanism reduce the number of memory access instructions to be used, 
and improve the utilization of the bus bandwidth.
In addition, DeAr allows the memory transfer to be initiated by two threads orthogonally under the hardware arbitration.
On the other hand, since two DeAr threads always branch simultaneously to the same basic block, 
the compiler can align their simultaneous instructions to adjacent addresses.
As a result, the instruction unit can serve two DeAr threads by doubling the fetch width instead of duplication of the hardware.
\\\indent
Next, we are looking into the datapath.
Two DeAr threads in a lane not only share group of arithmetic units that commonly exist in a RISC datapath, 
but also the same instruction unit which is suitable for synchronous branch.
The demonstrated example includes an adder, a multiplier and a barrel shifter, which are qualified to perform most benchmarks,
Nevertheless, the configuration of arithmetic units can be modified to fit the target applications.
The output of each arithmetic unit is an accumulator register, 
which bypasses the result to any arithmetic units that need it in the next clock cycle.
The bypassing-mechanism of accumulator registers avoid unnecessary accesses to RF, 
and thus reduce the energy dissipation in RF.
In addition, the accumulator registers are all clock-gated.
This enables DeAr to preserve the data in accumulator registers until the corresponding arithmetic unit is activated next time, 
offering more data bypassing opportunities.
The bypassing mechanism and resolution of structural hazards are both handled by the software, 
so the hardware complexity of dynamic scheduling or bypassing units can be avoided or reduced.
\\\indent
The RF is physically and symmetrically divided for two DeAr threads.
Each of them owns a pair of queue memory as well as stack memory, 
and these memory units of two DeAr threads form the sequential-accessed banked RF.
The banked organization of the RF cuts off redundant connectivity among read/write ports and register cells.
Compared with the conventional centralized organization, 
the wire area, power consumption and access time of the banked organization are significantly improved, as discussed in Section~\ref{sec:rfcell}.
A queue pair, composed of a load-queue and a store-queue, 
serves as the buffer that connects the lower level of the memory hierarchy with the datapath.
A load-queue and a store-queues can be accessed from their both sides concurrently in the first-in-first-out (FIFO) fashion.
A DeAr thread reads input data from its load-queue and writes the result of computation to its store-queue, 
while the load/store unit accesses the queues in the opposite direction.
By preventing a queue from empty or full with clever scheduling, the latency of load/store via it can thus be hidden.
The stack memory, on the other hand, is responsible for the storage of intermediate data and load/store address.
Other possible uses of the stack memory include branch condition evaluation and returning from interruption.
The nature of a stack memory is last-in-first-out (LIFO), 
which is the key property of the DeAr scheduling algorithm (elaborated in Chapter~\ref{cha:software}).
Using the sequential-access memory rather than a random-access one in RF effectively reduces the length of control signal, 
since any access to the RF can be simplified to "PUSH" or "POP".
The reduction in the length of control signal gains high code density and save the wiring from the instruction unit to RF.
This is the key advantage of DeAr over conventional VLIW architectures.
For clarity, we summarize the classification of various data registers in the datapath in Table~\ref{tab:register}.
\begin{table}[!ht]
    \caption{Classification of data registers in DeAr}
    \label{tab:register}
    \centering
    \begin{tabular}{|l|l|l|}
        \hline
        \multicolumn{1}{|c|}{\textbf{Register type}} & \multicolumn{1}{c|}{\textbf{Dedicated to}} & \multicolumn{1}{c|}{\textbf{Description}}                 \\ \hline
        Load-queue                                   & \multirow{3}{*}{a DeAr thread}             & buffers input data received from the main memory          \\ \cline{1-1} \cline{3-3} 
        Store-queue                                  &                                            & buffers output data sent to the main memroy               \\ \cline{1-1} \cline{3-3} 
        Stack                                        &                                            & buffers intermediate data of computation                  \\ \hline
        Accumulator                                  & an arithmetic unit                         & buffers the arithmetic result of the previous clock cycle \\ \hline
    \end{tabular}
\end{table}
\\\indent
The compact data bus separates the RF and arithmetic units with a set of multiplexers controlled by the instruction unit.
The route of data over the compact data bus is summarized as below:
\begin{itemize}
    \item Each arithmetic unit receives the first operand from a load-queue or an accumulator.
        and receives the second one from a load-queue or a stack.
    \item Each store-queue receives data from the output of an arithmetic unit.
    \item Each stack receives data from the output of an arithmetic unit.
\end{itemize}
It is important to note that, even though the communication among the RF, arithmetic units and accumulator registers is compacted exhaustively, 
the flexibility of the datapath is still be kept.
By such a compact design of the data bus, the further reduction in length of instructions can be achieved.
More insight into the compact data bus will be available in Section~\ref{sec:isa}.

\vspace{\textfig}
\begin{figure}[!ht] 
    \centering
    \includegraphics[width=0.85\textwidth]{./figs/micro.eps}
    \caption{Micro-architecture of a DeAr DSP lane}
    \label{fig:micro}
\end{figure}


\section{Instruction Set Architecture}
\label{sec:isa}
\indent The DeAr instruction set architecture (ISA) seemingly follows the principle of RISC, which takes instructions with fixed length, 
but the former is optimized for efficient arithmetic.
Each DeAr instruction is composed of two portions, RISC-style portion and stack-access portion.
%The instruction unit issues two instructions simultaneously for two DeAr threads.
Table~\ref{tab:risc} shows the functions of the RISC-style portion, which are similar to some subset conventional RISC ISA.
Here, we use the bold alphabets, \textbf{r}, \textbf{s}, \textbf{t}, \textbf{k}, \textbf{a}, 
to represent the instruction decode bit-fields and illustrate the meaning of each function.
According to their functions, they can be classified to three categories, A type, B type and M type.
A type includes arithmetic instructions such as addition (ADD or SUB), multiplication (MUL) and shift operation (SHL or SHR).
Other instructions like move (MV), which moves data from the other DeAr thread, 
and no operation (NOP), which stalls the DeAr thread for a cycle, 
belong to A type as well since they also manipulate arithmetic units.
B type includes instructions which interact with the instruction unit, such as branch on zero (BE), branch on nonzero (BNE) and unconditional branch (JMP).
M type, on the other, includes memory transfer instructions, load (LD) and store (ST), which manage the load/store unit.
%---------- risc-style portion table
\begin{table}[ht!]
    \centering
    \caption{RISC-style portion of the DeAr instruction set}
    \label{tab:risc}
    \begin{tabular}{|c|l|l|c|}
        \hline
        \multicolumn{1}{|c|}{\textbf{Category}} & \multicolumn{1}{c|}{\textbf{Name}} & \multicolumn{1}{c|}{\textbf{Meaning}} & \multicolumn{1}{c|}{\textbf{Target}} \\ \hline
    \multirow{7}{*}{ \begin{tabular}[c]{@{}l@{}} \\ A type \end{tabular}}      & ADD & \textbf{d} = \textbf{s} + \textbf{t}  & \multirow{7}{*}{\begin{tabular}[c]{@{}l@{}} \\ Datapath \end{tabular}}  \\ \cline{2-3}
                                                                               & SUB & \textbf{d} = \textbf{s} - \textbf{t} & \\ \cline{2-3} 
                                                                               & MUL & \textbf{d} = \textbf{s} * \textbf{t} & \\ \cline{2-3} 
                                                                               & SHL & \textbf{d} = \textbf{s} << \textbf{t} & \\ \cline{2-3}
                                                                               & SHR & \textbf{d} = \textbf{s} >> \textbf{t} & \\ \cline{2-3}
                                                                               & MV  & \textbf{d} = \textbf{s} + 0 or \textbf{d} = \textbf{s} << 0 & \\ \cline{2-3} 
                                                                               & NOP & \begin{tabular}[c]{@{}l@{}}1. disable write back \\ 2. clock-gate the accumulator \end{tabular}& \\ \hline
    \multirow{3}{*}{ \begin{tabular}[c]{@{}l@{}} \\ \\ B type \end{tabular}}          & JMP & pc = pc + \textbf{a}  & \multirow{3}{*}{ \begin{tabular}[c]{@{}l@{}} \\ \\ Instruction unit \end{tabular}} \\ \cline{2-3}
                                                                                      & BZ  & \begin{tabular}[c]{@{}l@{}} \textit{if}(stack1.read() == stack2.read())\\ \ \ \ \ \ \ \ pc = pc + \textbf{a} \end{tabular} & \\ \cline{2-3}
                                                                                      & BNZ & \begin{tabular}[c]{@{}l@{}} \textit{if}(stack1.read() != stack2.read())\\ \ \ \ \ \ \ \ pc = pc + \textbf{a} \end{tabular} & \\ \hline
    \multirow{2}{*}{ \begin{tabular}[c]{@{}l@{}} \\ M type \end{tabular}}           & LD  & \begin{tabular}[c]{@{}l@{}} \textit{repeat}(\textbf{r})\\ \ \ \ \ \ \ \ load\_queue.push (memory[\textbf{a}]) \end{tabular}& \multirow{2}{*}{\begin{tabular}[c]{@{}l@{}} \\  Load/store unit \end{tabular}} \\ \cline{2-3} 
                                                                                    & ST  & \begin{tabular}[c]{@{}l@{}} \textit{repeat}(\textbf{r})\\ \ \ \ \ \ \ \ memory[\textbf{a}] = store\_queue.pop() \end{tabular}& \\ \hline
    \end{tabular}
\end{table}
%-----------------------------------------

\indent 
On the other hand, the stack-access portion, illustrated in Table~\ref{tab:stack}, 
is dedicated to manipulate the stack memory of the DeAr thread.
The possible uses
Four stack operations, PUSH, POP, MODIFY and NOP, are defined, 
Each DeAr thread uses these stack operations to buffer its data in the LIFO manner.
A PUSH operation stores the result from one of arithmetic units and adds the head address by 1, 
while a POP operation eliminate the head data by subtracting the head address by 1.
Since a POP operation followed by a PUSH operation modifies the data at the head data and maintains the head address, 
a MODIFY operation is defined to simplify the usage of two operations.
In some scenarios, the DeAr thread does nothing to the stack but keeps its condition.
As a result, a NOP operation is also defined for the stack-access portion.
Note that the NOP of stack-access portion should be distinguished from the one of RISC-style portion.
These two portions constitute DeAr ISA.
The DeAr thread can thus access an arithmetic units with the RISC-style portion and handle the intermediate result with stack-access portion.
On the other hand, since the memory transfer instructions (i.e., LD and ST) never generate intermediate, 
they do not need the stack-access portion.
We can thus preserve more bits in the memory transfer instruction to address larger memory space.

%---------- stack portion table
\begin{table}[ht!]
    \centering
    \caption{Stack access portion of the DeAr instruction set}
    \label{tab:stack}
    \begin{tabular}{|l|l|l|}
        \hline
        \multicolumn{1}{|c|}{\textbf{Name}} & \multicolumn{1}{c|}{\textbf{Meaning}} & \multicolumn{1}{c|}{\textbf{Note}} \\ \hline
    PUSH & \begin{tabular}[c]{@{}l@{}}1. Add the head address by 1\\ 2. Write the new data to the head address\end{tabular} & \multirow{2}{*}{ \parbox{5cm}{A "pop" followed by a "push" is equivalent to a "modify"} } \\ \cline{1-2}
    POP                               & \begin{tabular}[c]{@{}l@{}}1. Subtract the head address by 1\\ 2. Invalidate the previous head data\end{tabular} & \\ \hline
        MODIFY                            & Modify the head data to to the new data & The head address remains \\ \hline
        NOP                               & No operation & The head address and data remain \\ \hline
    \end{tabular}
\end{table}
%-----------------------------------------

Each DeAr instruction is 12-bit in length.
To offer better insight into the instruction decode mechanism, 
Table~\ref{tab:decode} elaborates each bit-filed of various instruction types, 
which is enumerated from MSB to LSB and corresponds the bold alphabet in Table~\ref{tab:risc}.
Note that Table~\ref{tab:decode} also reveals the details of the compact data bus of Figure~\ref{fig:micro}, 
since the former describes the communication via the latter in detail.
There are five bit fields in an A-type instruction.
The head 4-bit signal \textbf{f}, which is similar to the function code in RISC, specifies the operation to be performed.
It is followed by a single-bit signal \textbf{d}, which determines whether the result of this operation is written back to the memory via the store-queue.
After that, a pair of 2-bit signals, \textbf{s} and \textbf{t}, select the sources of two arithmetic operands respectively. 
Nevertheless, the potential data sources of \textbf{s} and \textbf{t} are not identical.
The former selects the first operand from the load-queue or one of accumulator registers, 
while the latter selects the second one from the load-queue, stack, or constants (1 or 0).
The last 2-bit \textbf{k} is the stack access portion, which encodes four operations that manipulate the stack memory.
Note that both \textbf{f} and \textbf{s} are common to the other two types as well, 
and there is an unused bit in the A-type instruction.
\\\indent On the other hand, M-type instructions, include six bit fields.
The function field \textbf{f} is followed by a single bit \textbf{e}, which specifies data endianness in the memory.
Next, 2-bit signal \textbf{w}, specifies the word size of the transfer, which can be byte (8-bit), halfword (16-bit) or word (32-bit).
Another bit value \textbf{b} indicates whether the memory transfer is performed in the burst mode, 
and the following 2, \textbf{r}, determines the length of the burst (i.e., the number of transfers to be performed consecutively).
The burst length can be 2, 4, 8 or 16.
If \textbf{b} is de-asserted, \textbf{r} will be ignored.
\\\indent The last category, B-type instructions, is a special case compared with the previous two.
Since two DeAr threads always perform identical branch instructions simultaneously, 
two branch instructions can be merged into one with more bits for branch target addressing.
As a result, B-type instructions can manipulate 24-bit, which is twice of the original one in length.
The function field \textbf{f} is followed by 16-bit branch address offset \textbf{a}.
Likewise, the last 2-bit \textbf{k} denotes the stack access portion, which follows unused 2 bits.

%---------- bit field table---------------
\begin{table}[!ht]
    \centering
    \caption{Instrucion decode table of the DeAr instrucion set}
    \label{tab:decode}
    \begin{tabular}{|l|l|l|}
        \hline
        \multicolumn{1}{|c|}{\textbf{Mark}} & \multicolumn{1}{c|}{\textbf{Bit field}} & \multicolumn{1}{c|}{\textbf{Description}} \\ \hline
        \multicolumn{3}{|c|}{\textbf{A-type instructions}} \\ \hline
    f & {[}11:8{]} & \begin{tabular}[c]{@{}l@{}}Specify the function of this instruction, which can \\ be ADD, SUB, SHL, SHR, MUL, MV or NOP\end{tabular} \\ \hline
    d & {[}7{]} & \begin{tabular}[c]{@{}l@{}}Determine whether the arithmetic result is written \\ back to the store-queue\end{tabular} \\ \hline
    s & {[}6:5{]} & \begin{tabular}[c]{@{}l@{}}Specify the source of the first arithmetic operand, \\ which can be the load-queue or one of accumulators\end{tabular} \\ \hline
    t & {[}4:3{]} & \begin{tabular}[c]{@{}l@{}}Specify the source of the second arithmetic operand, \\ which can be the load-queue, stack, constant 0 or 1\end{tabular} \\ \hline
    k & {[}1:0{]} & \begin{tabular}[c]{@{}l@{}}Specify the stack operation, which can be PUSH, POP, \\ MODIFY or NOP (stack access portion)\end{tabular} \\ \hline
        \multicolumn{3}{|c|}{\textbf{M-type instructions}} \\ \hline
    f & {[}11:8{]} & \begin{tabular}[c]{@{}l@{}}Specify the function of this instruction, which can \\ be LD or ST\end{tabular} \\ \hline
    e & {[}7{]} & \begin{tabular}[c]{@{}l@{}}Specify the endianness of the data in the memory \end{tabular} \\ \hline
    w & {[}6:5{]} & \begin{tabular}[c]{@{}l@{}}Specify the word size of the data in the memory, \\ which can be byte, halfword or word \end{tabular} \\ \hline
    b & {[}4{]} & \begin{tabular}[c]{@{}l@{}}Specify whether the memory transfer is performed in \\ the burst mode \end{tabular} \\ \hline
    r & {[}3:2{]} & \begin{tabular}[c]{@{}l@{}}Specify the burst length of the burst mode transfer, \\ which can be 2, 4, 8 or 16 \end{tabular} \\ \hline
    k & {[}1:0{]} & \begin{tabular}[c]{@{}l@{}}Specify the stack operation, which can be PUSH, POP, \\ MODIFY or NOP (stack access portion)\end{tabular} \\ \hline
        \multicolumn{3}{|c|}{\textbf{B-type instructions}} \\ \hline
    f & {[}23:20{]} & \begin{tabular}[c]{@{}l@{}}Specify the function of this instruction, which can \\ be BE or BNE\end{tabular} \\ \hline
    a & {[}19:4{]} & \begin{tabular}[c]{@{}l@{}}Specify the branch address offset \end{tabular} \\ \hline
    k & {[}1:0{]} & \begin{tabular}[c]{@{}l@{}}Specify the stack operation, which can be PUSH, POP, \\ MODIFY or NOP (stack access portion)\end{tabular} \\ \hline
    \end{tabular}
\end{table}
%------------------------------------------
\newpage
\section{Framework of Multi-core Design}
In addition to the processing core implementation, we also propose a framework of multi-core design for DeAr.

